# üìä Churn Prediction SaaS Project

> **Advanced Telco Customer Churn Prediction Platform** ‚Äî A production-grade, end-to-end machine learning system that predicts customer churn, explains predictions, recommends retention actions, and monitors model performance in real time.

---

## üèóÔ∏è Architecture Overview

```
ChurnPredictionSaasProject/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml              # Master configuration (paths, hyperparams, thresholds)
‚îú‚îÄ‚îÄ src/                          # Core ML package
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loader.py            # Data ingestion & cleaning
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validator.py         # Schema & quality validation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocessor.py      # Encoding, scaling, train/test split
‚îÇ   ‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ engineer.py          # 30+ engineered features (tenure, charge, service, interaction)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ selector.py          # Correlation, mutual info, tree-based feature selection
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trainer.py           # Multi-model training (LR, RF, XGBoost, LightGBM)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluator.py         # ROC-AUC, PR-AUC, lift@k, expected profit, calibration plots
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ explainer.py         # SHAP-based global & local explanations + what-if analysis
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ registry.py          # File-based model versioning & promotion
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ drift.py             # PSI-based feature & prediction drift detection
‚îÇ   ‚îú‚îÄ‚îÄ actions/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ recommender.py       # ROI-optimized next-best-action retention recommendations
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îî‚îÄ‚îÄ helpers.py           # Config loading, logging, model I/O, path utilities
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                  # FastAPI app (predict, batch, what-if, health endpoints)
‚îÇ   ‚îî‚îÄ‚îÄ schemas.py               # Pydantic v2 request/response models with validation
‚îú‚îÄ‚îÄ dashboard/
‚îÇ   ‚îî‚îÄ‚îÄ app.py                   # Streamlit interactive dashboard (6 pages)
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ train.py                 # Full training pipeline orchestrator
‚îÇ   ‚îî‚îÄ‚îÄ predict.py               # Batch prediction with CLI arguments
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_data.py             # Data pipeline unit tests
‚îÇ   ‚îú‚îÄ‚îÄ test_features.py         # Feature engineering tests
‚îÇ   ‚îî‚îÄ‚îÄ test_models.py           # Model training & evaluation tests
‚îú‚îÄ‚îÄ data/raw/                    # Raw input data (CSV)
‚îú‚îÄ‚îÄ data/processed/              # Processed outputs
‚îú‚îÄ‚îÄ models/                      # Saved models, preprocessors, thresholds
‚îú‚îÄ‚îÄ logs/                        # Application logs
‚îú‚îÄ‚îÄ reports/                     # Evaluation plots & drift reports
‚îú‚îÄ‚îÄ requirements.txt             # All Python dependencies
‚îî‚îÄ‚îÄ .gitignore                   # Comprehensive ignore rules
```

---

## üöÄ Key Features

### üß† Advanced Machine Learning

- **4 algorithms**: Logistic Regression, Random Forest, XGBoost, LightGBM
- **Probability calibration** via Isotonic Regression for reliable risk scores
- **Cost-sensitive threshold optimization** maximizing expected profit (not just accuracy)
- **Automated hyperparameter configuration** via YAML config

### üî¨ Feature Engineering (30+ Features)

- **Tenure features**: years, groups, bins, new customer flag, loyalty score
- **Charge features**: average per month, charge ratio, overpayment detection, spending tier
- **Service features**: total service count, has security, has streaming, digital engagement
- **Contract features**: risk score, auto-pay indicator, commitment level
- **Interaction features**: tenure √ó charges, contract √ó internet, senior √ó support

### üìä Evaluation Beyond Accuracy

- ROC-AUC and PR-AUC with publication-quality curves
- **Lift@k%** ‚Äî how many more churners you catch in the top k%
- **Expected profit curve** ‚Äî find the threshold that maximizes business value
- **Calibration plots** ‚Äî verify that a "60% risk" score is truly 60%
- Side-by-side model comparison dashboard

### üîç Explainability (SHAP)

- **Global importance** ‚Äî which features matter most across all customers
- **Local explanations** ‚Äî why THIS customer is predicted to churn
- **What-if analysis** ‚Äî "what happens if we upgrade their contract?"
- SHAP summary and waterfall plots (auto-saved)

### ‚ö†Ô∏è Drift Monitoring

- **Population Stability Index (PSI)** for every feature
- Prediction distribution drift detection
- Performance decay monitoring over time
- Configurable warning and alert thresholds

### üéØ Next-Best-Action Engine

- **15-action catalog** across 5 categories (pricing, contract, service, payment, engagement)
- **ROI-based ranking** ‚Äî each action estimates cost, success rate, and expected value
- **Personalized retention plans** with priority and implementation timeline
- **Customer prioritization** by expected revenue loss

### üåê REST API (FastAPI)

- `POST /predict` ‚Äî single customer prediction with risk level
- `POST /predict/batch` ‚Äî score hundreds of customers at once
- `POST /whatif` ‚Äî simulate feature changes
- `GET /health` ‚Äî model status and version info
- CORS-enabled, production-ready with async support

### üì± Interactive Dashboard (Streamlit)

- **Overview** ‚Äî KPIs, risk distribution pie chart, monthly trend
- **Customer Analysis** ‚Äî form-based individual prediction with gauge chart
- **What-If Simulator** ‚Äî interactive feature manipulation
- **Model Performance** ‚Äî evaluation plots and model comparison table
- **Drift Monitoring** ‚Äî PSI trends and feature stability status
- **Batch Predictions** ‚Äî CSV upload ‚Üí download scored results

---

## ‚ö° Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/wasam0110/Churn-Saas_project.git
cd Churn-Saas_project
```

### 2. Create a Virtual Environment

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Train the Model

```bash
python scripts/train.py
```

> This will auto-generate synthetic data if no real data is present, train all 4 models, calibrate probabilities, optimize thresholds, compute SHAP explanations, and register the best model.

### 5. Launch the API

```bash
uvicorn api.main:app --host 0.0.0.0 --port 8000 --reload
```

Visit: [http://localhost:8000/docs](http://localhost:8000/docs) for the interactive Swagger UI.

### 6. Launch the Dashboard

```bash
streamlit run dashboard/app.py --server.port 8501
```

Visit: [http://localhost:8501](http://localhost:8501)

### 7. Run Batch Predictions

```bash
python scripts/predict.py --input data/raw/telco_churn.csv --output data/processed/predictions.csv --actions
```

### 8. Run Tests

```bash
pytest tests/ -v
```

---

## üîå API Reference

### `POST /predict`

```json
{
  "gender": "Female",
  "SeniorCitizen": 0,
  "Partner": "Yes",
  "Dependents": "No",
  "tenure": 12,
  "PhoneService": "Yes",
  "MultipleLines": "No",
  "InternetService": "Fiber optic",
  "OnlineSecurity": "No",
  "OnlineBackup": "Yes",
  "DeviceProtection": "No",
  "TechSupport": "No",
  "StreamingTV": "Yes",
  "StreamingMovies": "No",
  "Contract": "Month-to-month",
  "PaperlessBilling": "Yes",
  "PaymentMethod": "Electronic check",
  "MonthlyCharges": 84.45,
  "TotalCharges": 1013.4
}
```

**Response:**

```json
{
  "churn_probability": 0.7234,
  "churn_prediction": true,
  "risk_level": "HIGH",
  "threshold_used": 0.45,
  "model_version": "xgboost_v1"
}
```

### `POST /predict/batch`

Send an array of customers and receive predictions for all of them.

### `POST /whatif`

Simulate changing one feature and see the impact on churn probability.

### `GET /health`

Check model status, version, and uptime.

---

## üìã Configuration

All settings are centralized in `config/config.yaml`:

| Section           | Parameters                                     |
| ----------------- | ---------------------------------------------- |
| **data**          | Paths, column names, target encoding           |
| **features**      | Tenure bins, rolling windows, service columns  |
| **preprocessing** | Test size, random state, scaling method        |
| **models**        | Algorithms, hyperparameters for LR/RF/XGB/LGBM |
| **calibration**   | Method (isotonic/sigmoid), CV folds            |
| **threshold**     | Retention cost ($50), customer value ($500)    |
| **monitoring**    | PSI thresholds (0.1 warning, 0.2 drift)        |
| **api**           | Host, port, CORS origins                       |
| **dashboard**     | Streamlit port, theme                          |

---

## üß™ Testing

```bash
# Run all tests with verbose output
pytest tests/ -v

# Run specific test modules
pytest tests/test_data.py -v
pytest tests/test_features.py -v
pytest tests/test_models.py -v

# Run with coverage report
pytest tests/ --cov=src --cov-report=html
```

---

## üì¶ Tech Stack

| Category           | Technologies                                      |
| ------------------ | ------------------------------------------------- |
| **ML/DS**          | scikit-learn, XGBoost, LightGBM, imbalanced-learn |
| **Explainability** | SHAP, waterfall & summary plots                   |
| **API**            | FastAPI, Pydantic v2, Uvicorn                     |
| **Dashboard**      | Streamlit, Plotly                                 |
| **MLOps**          | MLflow, Evidently, custom model registry          |
| **Data**           | Pandas, NumPy, PyYAML                             |
| **Testing**        | pytest, pytest-cov                                |
| **Logging**        | Loguru                                            |

---

## üìà What Makes This Project Stand Out

1. **Business-Value Optimization** ‚Äî Doesn't just maximize accuracy; optimizes the threshold for maximum expected profit using configurable retention costs and customer lifetime value.

2. **Calibrated Probabilities** ‚Äî Uses isotonic regression calibration so that a "60% churn risk" truly means 60%.

3. **Full Explainability Stack** ‚Äî SHAP-based global importance, per-customer explanations, and what-if analysis for actionable insights.

4. **Next-Best-Action Engine** ‚Äî Goes beyond prediction to recommend specific retention actions ranked by ROI.

5. **Drift Monitoring** ‚Äî PSI-based feature and prediction drift detection to know when the model needs retraining.

6. **Production Architecture** ‚Äî FastAPI backend, Streamlit dashboard, model registry with versioning, and comprehensive logging.

7. **Every Line Commented** ‚Äî Every single line of code has an explanatory comment for maximum readability and learning.

---

## üìÑ License

This project is for educational and portfolio purposes.

---

## üë§ Author

Built with ‚ù§Ô∏è as an advanced data science portfolio project.

## Getting started

1. Install dependencies (see project files for language-specific requirements).
2. Run preprocessing and training scripts to prepare the model.
3. Start the web service to serve predictions.

## Development

- Add your project files into this repository.
- Commit and push changes to the `main` branch.

## Remote

Repository remote: https://github.com/wasam0110/Churn-Saas_project.git

---
